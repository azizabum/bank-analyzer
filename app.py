#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù…Ø­Ù„Ù„ ÙƒØ´ÙˆÙ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¨Ù†ÙƒÙŠØ© - Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¯Ù…ÙˆØ¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
ÙˆØ§Ø¬Ù‡Ø© ÙˆÙŠØ¨ Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… ÙˆÙ†Ø¸Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ + ngrok
ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ ÙˆØ¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ
"""

# ==================== Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ÙˆØ§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª ====================
from flask import Flask, render_template, request, jsonify, send_file, url_for, redirect
from werkzeug.utils import secure_filename
import os
import uuid
from datetime import datetime, timedelta
import tempfile
import shutil
from threading import Timer
import logging
import re
from collections import defaultdict
import numpy as np
import subprocess
import time
import requests
import sys
import codecs

# Ù…ÙƒØªØ¨Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© PDF
import pdfplumber
try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
except ImportError:
    PYMUPDF_AVAILABLE = False

# Ù…ÙƒØªØ¨Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
import arabic_reshaper
from bidi.algorithm import get_display

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ
from expense_categories import (
    classify_transaction,
    get_category_statistics,
    format_category_report,
    EXPENSE_CATEGORIES,
    classify_alrajhi_transaction  # Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ ÙÙŠ expense_categories
)

# ==================== Ø¯ÙˆØ§Ù„ ngrok ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… ====================

# Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªØ±Ù…ÙŠØ² ÙÙŠ Windows
if sys.platform.startswith('win'):
    try:
        os.system('chcp 65001 > nul')
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())
    except:
        pass

def safe_print(text):
    """Ø·Ø¨Ø§Ø¹Ø© Ø¢Ù…Ù†Ø© ØªØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªØ±Ù…ÙŠØ²"""
    try:
        print(text)
    except UnicodeEncodeError:
        safe_text = text.encode('ascii', 'replace').decode('ascii')
        print(safe_text)

def get_ngrok_url():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· ngrok"""
    try:
        time.sleep(3)
        response = requests.get('http://localhost:4040/api/tunnels', timeout=5)
        tunnels = response.json()['tunnels']

        for tunnel in tunnels:
            if tunnel['proto'] == 'https':
                return tunnel['public_url']
        return None
    except:
        return None

def start_ngrok():
    """ØªØ´ØºÙŠÙ„ ngrok"""
    try:
        subprocess.Popen(['ngrok', 'http', '5000'], 
                        stdout=subprocess.DEVNULL, 
                        stderr=subprocess.DEVNULL)
        return True
    except FileNotFoundError:
        safe_print("âŒ ngrok ØºÙŠØ± Ù…Ø«Ø¨Øª!")
        safe_print("ğŸ’¡ Ø«Ø¨Øª ngrok Ù…Ù†: https://ngrok.com/download")
        safe_print("   Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù…: npm install -g ngrok")
        return False

def start_with_ngrok():
    """ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹ ngrok"""
    safe_print("ğŸš€ ØªØ´ØºÙŠÙ„ Ù…Ø­Ù„Ù„ ÙƒØ´Ù Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¹ ngrok...")
    safe_print("âš¡ Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø£Ø²Ø±Ù‚ ÙÙŠ ÙˆØ§ØªØ³Ø§Ø¨")
    safe_print("=" * 50)

    # ØªØ´ØºÙŠÙ„ ngrok ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
    safe_print("ğŸ”„ ØªØ´ØºÙŠÙ„ ngrok...")
    if not start_ngrok():
        return False

    # Ø§Ù†ØªØ¸Ø§Ø± ÙˆØ§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø·
    safe_print("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ...")

    ngrok_url = None
    for attempt in range(10):
        ngrok_url = get_ngrok_url()
        if ngrok_url:
            break
        time.sleep(1)
        safe_print(f"   Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}/10...")

    if ngrok_url:
        os.environ['EXTERNAL_URL'] = ngrok_url
        safe_print(f"âœ… Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ Ø¬Ø§Ù‡Ø²: {ngrok_url}")
        safe_print("ğŸ”µ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¢Ù† Ø³ØªÙƒÙˆÙ† Ø²Ø±Ù‚Ø§Ø¡ ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø¶ØºØ· ÙÙŠ ÙˆØ§ØªØ³Ø§Ø¨!")
    else:
        safe_print("âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· ngrok")
        safe_print("ğŸ” Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø­Ù„ÙŠ")

    safe_print("\nğŸ“± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©:")
    safe_print(f"ğŸ  Ù…Ø­Ù„ÙŠ:  http://localhost:5000")
    if ngrok_url:
        safe_print(f"ğŸŒ Ø®Ø§Ø±Ø¬ÙŠ: {ngrok_url}")
        safe_print("âœ… Ø´Ø§Ø±Ùƒ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø· Ø²Ø±Ù‚Ø§Ø¡!")

    safe_print("\n" + "=" * 50)
    safe_print("ğŸƒâ€â™‚ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚...")
    
    return True

# ==================== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ====================
app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
app.config['MAX_CONTENT_LENGTH'] = 32 * 1024 * 1024  # 32 MB max file size
app.config['UPLOAD_FOLDER'] = tempfile.mkdtemp()

# Ù‚Ø§Ù…ÙˆØ³ Ù„Ø­ÙØ¸ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù†Ø´Ø·Ø©
active_links = {}

# Ø¥Ø¹Ø¯Ø§Ø¯ logging
logging.basicConfig(level=logging.INFO)

# Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ù…Ù„ÙØ§Øª PDF ÙÙ‚Ø·
ALLOWED_EXTENSIONS = {'pdf'}

# ==================== Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ====================

def fix_arabic_text_advanced(text):
    """Ø¥ØµÙ„Ø§Ø­ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† PDF"""
    if not text:
        return ""
    
    text = str(text).strip()
    
    # Ø¥Ø²Ø§Ù„Ø© Ø£Ø­Ø±Ù Ø§Ù„ØªØ­ÙƒÙ…
    text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)
    text = re.sub(r'[\u200B-\u200F\u202A-\u202E\u2066-\u2069]', '', text)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹ÙƒÙˆØ³
    if is_text_reversed(text):
        text = reverse_mixed_text(text)
    
    # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…Ù†ÙØµÙ„Ø©
    text = fix_separated_arabic_chars(text)
    
    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
    text = normalize_numbers(text)
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… arabic_reshaper
    try:
        configuration = {
            'delete_harakat': False,
            'shift_harakat_position': True,
            'support_ligatures': True,
            'use_unshaped_instead_of_isolated': False
        }
        reshaper = arabic_reshaper.ArabicReshaper(configuration=configuration)
        reshaped = reshaper.reshape(text)
        text = get_display(reshaped)
    except:
        text = manual_arabic_fix(text)
    
    # ØªÙ†Ø¸ÙŠÙ Ù†Ù‡Ø§Ø¦ÙŠ
    text = final_cleanup(text)
    
    return text

def is_text_reversed(text):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù†Øµ Ù…Ø¹ÙƒÙˆØ³"""
    patterns = [
        r'^[A-Za-z\s\d]+[\u0600-\u06FF]',
        r'[\u0600-\u06FF]\s*\d+\s*$',
        r'^\d{2}[-/]\d{2}[-/]\d{4}.*[\u0600-\u06FF]',
    ]
    
    for pattern in patterns:
        if re.search(pattern, text):
            return True
    
    reversed_words = ['Ù„Ø§ÙŠØ±', 'ÙŠØ¯ÙˆØ¹Ø³', 'ØªÙŠÙˆÙƒ', 'Ø±Ø·Ù‚', 'Ù†ÙŠØ±Ø­Ø¨']
    for word in reversed_words:
        if word in text:
            return True
    
    return False

def reverse_mixed_text(text):
    """Ø¹ÙƒØ³ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø®ØªÙ„Ø· Ø¨Ø°ÙƒØ§Ø¡"""
    parts = []
    current = []
    current_type = None
    
    for char in text:
        if '\u0600' <= char <= '\u06FF':
            char_type = 'arabic'
        elif char.isdigit():
            char_type = 'digit'
        elif char.isalpha():
            char_type = 'english'
        else:
            char_type = 'other'
        
        if current_type != char_type:
            if current:
                if current_type == 'arabic':
                    parts.append(''.join(reversed(current)))
                else:
                    parts.append(''.join(current))
                current = []
            current_type = char_type
        
        current.append(char)
    
    if current:
        if current_type == 'arabic':
            parts.append(''.join(reversed(current)))
        else:
            parts.append(''.join(current))
    
    return ' '.join(parts)

def fix_separated_arabic_chars(text):
    """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…Ù†ÙØµÙ„Ø©"""
    text = re.sub(r'([\u0600-\u06FF])\s+([\u0600-\u06FF])', r'\1\2', text)
    
    replacements = {
        'Ø§ Ù„': 'Ø§Ù„',
        'Ùˆ Ø§': 'ÙˆØ§',
        'ÙŠ Ø§': 'ÙŠØ§',
        'Ù‡ Ø§': 'Ù‡Ø§',
        'Ù… Ù†': 'Ù…Ù†',
        'Ù ÙŠ': 'ÙÙŠ',
        'Ø¥ Ù„ Ù‰': 'Ø¥Ù„Ù‰',
        'Ø¹ Ù„ Ù‰': 'Ø¹Ù„Ù‰',
        'Ù‡ Ø° Ø§': 'Ù‡Ø°Ø§',
        'Ù‡ Ø° Ù‡': 'Ù‡Ø°Ù‡',
        'Ø° Ù„ Ùƒ': 'Ø°Ù„Ùƒ',
        'Ø§ Ù„ Ø³ Ø¹ Ùˆ Ø¯ ÙŠ': 'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ',
        'Ø§ Ù„ Ø± ÙŠ Ø§ Ø¶': 'Ø§Ù„Ø±ÙŠØ§Ø¶',
        'Ø§ Ù„ Ù… Ù… Ù„ Ùƒ Ø©': 'Ø§Ù„Ù…Ù…Ù„ÙƒØ©',
    }
    
    for old, new in replacements.items():
        text = text.replace(old, new)
    
    return text

def normalize_numbers(text):
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ù‡Ù†Ø¯ÙŠØ©"""
    arabic_indic_digits = 'Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©'
    western_digits = '0123456789'
    
    trans_table = str.maketrans(arabic_indic_digits, western_digits)
    text = text.translate(trans_table)
    
    return text

def manual_arabic_fix(text):
    """Ø¥ØµÙ„Ø§Ø­ ÙŠØ¯ÙˆÙŠ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
    common_fixes = {
        'Ø©ÙŠØ¯ÙˆØ¹Ø³Ù„Ø§': 'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©',
        'Ø¶Ø§ÙŠØ±Ù„Ø§': 'Ø§Ù„Ø±ÙŠØ§Ø¶',
        'Ø©Ø¯Ø¬': 'Ø¬Ø¯Ø©',
        'Ø©ÙƒÙ…': 'Ù…ÙƒØ©',
        'Ù…Ø§Ù…Ø¯Ù„Ø§': 'Ø§Ù„Ø¯Ù…Ø§Ù…',
        'Ø±Ø¨Ø®Ù„Ø§': 'Ø§Ù„Ø®Ø¨Ø±',
        'Ø¡Ø§Ø±Ø´': 'Ø´Ø±Ø§Ø¡',
        'Ø¹ÙŠØ¨': 'Ø¨ÙŠØ¹',
        'Ù„ÙŠÙˆØ­Øª': 'ØªØ­ÙˆÙŠÙ„',
        'Ø¨Ø­Ø³': 'Ø³Ø­Ø¨',
        'Ø¹Ø§Ø¯ÙŠØ¥': 'Ø¥ÙŠØ¯Ø§Ø¹',
        'Ø©ÙŠÙ„Ù…Ø¹': 'Ø¹Ù…Ù„ÙŠØ©',
        'ÙØ§Ø±Øµ': 'ØµØ±Ø§Ù',
        'ÙŠÙ„Ø¢': 'Ø¢Ù„ÙŠ',
        'Ø©Ù‚Ø§Ø·Ø¨': 'Ø¨Ø·Ø§Ù‚Ø©',
        'Ù†Ø§Ù…ØªØ¦Ø§': 'Ø§Ø¦ØªÙ…Ø§Ù†',
        'Ù…ÙˆØ³Ø±': 'Ø±Ø³ÙˆÙ…',
        'Ø©Ù…Ø¯Ø®': 'Ø®Ø¯Ù…Ø©',
        'ÙƒÙ†Ø¨': 'Ø¨Ù†Ùƒ',
        'ÙŠÙ„Ù‡Ù„Ø£Ø§': 'Ø§Ù„Ø£Ù‡Ù„ÙŠ',
        'Ø¨Ø§Ø³Ø­': 'Ø­Ø³Ø§Ø¨',
        'Ø¯ÙŠØµØ±': 'Ø±ØµÙŠØ¯',
        'Ù„Ø§ÙŠØ±': 'Ø±ÙŠØ§Ù„',
        'Ø®ÙŠØ±Ø§Øª': 'ØªØ§Ø±ÙŠØ®',
        'ØºÙ„Ø¨Ù…': 'Ù…Ø¨Ù„Øº',
        'ÙØµÙˆ': 'ÙˆØµÙ',
    }
    
    for wrong, correct in common_fixes.items():
        text = text.replace(wrong, correct)
    
    return text

def final_cleanup(text):
    """Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù†Øµ"""
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    text = re.sub(r'\s+([.,ØŒØ›:])', r'\1', text)
    text = re.sub(r'([.,ØŒØ›:])\s*', r'\1 ', text)
    
    return text

def fix_dots_text(text):
    """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªÙŠ ØªØ¸Ù‡Ø± ÙƒÙ†Ù‚Ø§Ø·"""
    if not text:
        return ""
    
    if all(c in '...â€¢â€¤â€¥â€¦â‹¯â‹®â‹°â‹±' or ord(c) > 65000 for c in str(text).strip()):
        return "[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]"
    
    return text

def extract_text_properly(cell_text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ Ù…Ù† Ø®Ù„ÙŠØ© PDF"""
    if not cell_text:
        return ""
    
    text = str(cell_text)
    
    if text.strip() in ['...', '***', 'â€¢â€¢â€¢', '']:
        return "[Ù…Ø­ØªÙˆÙ‰ Ù…Ø®ÙÙŠ]"
    
    try:
        if '\\x' in repr(text) or '\\u' in repr(text):
            text = text.encode('latin-1').decode('utf-8', errors='ignore')
    except:
        pass
    
    return text

def deep_fix_arabic_text(text):
    """Ø¥ØµÙ„Ø§Ø­ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©"""
    if not text or text == "[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]" or text == "[Ù…Ø­ØªÙˆÙ‰ Ù…Ø®ÙÙŠ]":
        return text
    
    text = str(text).strip()
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø®Ø§Ø·Ø¦Ø©
    encodings = ['utf-8', 'windows-1256', 'iso-8859-6', 'cp720', 'cp1256']
    for encoding in encodings:
        try:
            fixed = text.encode('latin-1').decode(encoding)
            if any('\u0600' <= c <= '\u06FF' for c in fixed):
                text = fixed
                break
        except:
            continue
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ§Ù„ÙÙˆØ§ØµÙ„
    text = fix_arabic_spacing(text)
    
    # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…Ù†ÙØµÙ„Ø©
    text = join_arabic_letters(text)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© reshaper
    try:
        configuration = {
            'delete_harakat': False,
            'shift_harakat_position': True,
            'support_ligatures': True,
            'language': 'Arabic'
        }
        reshaper = arabic_reshaper.ArabicReshaper(configuration=configuration)
        text = reshaper.reshape(text)
        text = get_display(text)
    except:
        pass
    
    # Ø¥ØµÙ„Ø§Ø­ ÙƒÙ„Ù…Ø§Øª Ø¨Ù†ÙƒÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
    text = fix_common_banking_words(text)
    
    return text

def fix_arabic_spacing(text):
    """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
    text = re.sub(r'([\u0600-\u06FF])\s+([\u0600-\u06FF])', r'\1\2', text)
    text = re.sub(r'Ø§\s+Ù„\s*', 'Ø§Ù„', text)
    return text

def join_arabic_letters(text):
    """Ø±Ø¨Ø· Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…Ù†ÙØµÙ„Ø©"""
    letter_fixes = {
        'Ø§ Ù„ Ø³ Ø¹ Ùˆ Ø¯ ÙŠ': 'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ',
        'Ø§ Ù„ Ø³ Ø¹ Ùˆ Ø¯ ÙŠ Ø©': 'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©',
        'Ø§ Ù„ Ø£ Ù‡ Ù„ ÙŠ': 'Ø§Ù„Ø£Ù‡Ù„ÙŠ',
        'Ø§ Ù„ Ø¨ Ù† Ùƒ': 'Ø§Ù„Ø¨Ù†Ùƒ',
        'Ø§ Ù„ Ø± ÙŠ Ø§ Ø¶': 'Ø§Ù„Ø±ÙŠØ§Ø¶',
        'Øª Ø­ Ùˆ ÙŠ Ù„': 'ØªØ­ÙˆÙŠÙ„',
        'Ø³ Ø­ Ø¨': 'Ø³Ø­Ø¨',
        'Ø¥ ÙŠ Ø¯ Ø§ Ø¹': 'Ø¥ÙŠØ¯Ø§Ø¹',
        'Ø¹ Ù… Ù„ ÙŠ Ø©': 'Ø¹Ù…Ù„ÙŠØ©',
        'Ø± ÙŠ Ø§ Ù„': 'Ø±ÙŠØ§Ù„',
        'Ø­ Ø³ Ø§ Ø¨': 'Ø­Ø³Ø§Ø¨',
        'Ø± Øµ ÙŠ Ø¯': 'Ø±ØµÙŠØ¯',
        'Øµ Ø± Ø§ Ù': 'ØµØ±Ø§Ù',
        'Ø¢ Ù„ ÙŠ': 'Ø¢Ù„ÙŠ',
        'Ø¨ Ø· Ø§ Ù‚ Ø©': 'Ø¨Ø·Ø§Ù‚Ø©',
        'Ø§ Ø¦ Øª Ù… Ø§ Ù†': 'Ø§Ø¦ØªÙ…Ø§Ù†',
        'Ø± Ø³ Ùˆ Ù…': 'Ø±Ø³ÙˆÙ…',
        'Ø® Ø¯ Ù… Ø©': 'Ø®Ø¯Ù…Ø©',
        'Ù… Ø¨ Ù„ Øº': 'Ù…Ø¨Ù„Øº',
        'Øª Ø§ Ø± ÙŠ Ø®': 'ØªØ§Ø±ÙŠØ®',
        'Ùˆ Øµ Ù': 'ÙˆØµÙ',
        'Ø´ Ø± Ø§ Ø¡': 'Ø´Ø±Ø§Ø¡',
        'Ø¨ ÙŠ Ø¹': 'Ø¨ÙŠØ¹',
        'Ø¯ Ù Ø¹': 'Ø¯ÙØ¹',
        'Ù† Ù‚ Ø¯ ÙŠ': 'Ù†Ù‚Ø¯ÙŠ',
        'Ø´ ÙŠ Ùƒ': 'Ø´ÙŠÙƒ',
        'Ù Ø§ Øª Ùˆ Ø± Ø©': 'ÙØ§ØªÙˆØ±Ø©',
        'Ù… Ø¯ Ù Ùˆ Ø¹ Ø§ Øª': 'Ù…Ø¯ÙÙˆØ¹Ø§Øª',
        'Ù… Øµ Ø± Ùˆ Ù Ø§ Øª': 'Ù…ØµØ±ÙˆÙØ§Øª',
        'Ø¥ ÙŠ Ø± Ø§ Ø¯ Ø§ Øª': 'Ø¥ÙŠØ±Ø§Ø¯Ø§Øª',
    }
    
    for separated, joined in letter_fixes.items():
        text = text.replace(separated, joined)
    
    return text

def fix_common_banking_words(text):
    """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ù†ÙƒÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
    banking_fixes = {
        'ÙŠÙ„Ù‡Ù„Ø£Ø§ ÙƒÙ†Ø¨Ù„Ø§': 'Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ',
        'ÙŠÙ„Ù‡Ù„Ø§Ø§ ÙƒÙ†Ø¨Ù„Ø§': 'Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ',
        'ÙŠØ¯ÙˆØ¹Ø³Ù„Ø§ ÙŠÙ„Ù‡Ù„Ø£Ø§': 'Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ',
        'ÙŠØ¯ÙˆØ¹Ø³Ù„Ø§ ÙŠÙ„Ù‡Ù„Ø§Ø§': 'Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ',
        'ÙƒÙ†Ø¨Ù„Ø§ ÙŠÙ„Ù‡Ù„Ø£Ø§': 'Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ',
        'ÙƒÙ†Ø¨Ù„Ø§ ÙŠÙ„Ù‡Ù„Ø§Ø§': 'Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ',
        'Ø¶Ø§ÙŠØ±Ù„Ø§': 'Ø§Ù„Ø±ÙŠØ§Ø¶',
        'Ø©Ø¯Ø¬': 'Ø¬Ø¯Ø©',
        'Ø©ÙƒÙ…': 'Ù…ÙƒØ©',
        'Ø©Ù†ÙŠØ¯Ù…Ù„Ø§': 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©',
        'Ù…Ø§Ù…Ø¯Ù„Ø§': 'Ø§Ù„Ø¯Ù…Ø§Ù…',
        'Ø±Ø¨Ø®Ù„Ø§': 'Ø§Ù„Ø®Ø¨Ø±',
        'ÙØ¦Ø§Ø·Ù„Ø§': 'Ø§Ù„Ø·Ø§Ø¦Ù',
        'Ù„ÙŠØ¨Ø¬Ù„Ø§': 'Ø§Ù„Ø¬Ø¨ÙŠÙ„',
        'Ø¬Ø±Ø®Ù„Ø§': 'Ø§Ù„Ø®Ø±Ø¬',
        'Ù„ÙŠÙˆØ­Øª': 'ØªØ­ÙˆÙŠÙ„',
        'Ø¨Ø­Ø³': 'Ø³Ø­Ø¨',
        'Ø¹Ø§Ø¯ÙŠØ¥': 'Ø¥ÙŠØ¯Ø§Ø¹',
        'Ø©ÙŠÙ„Ù…Ø¹': 'Ø¹Ù…Ù„ÙŠØ©',
        'Ø¯Ø§Ø¯Ø³': 'Ø³Ø¯Ø§Ø¯',
        'Ø¹ÙØ¯': 'Ø¯ÙØ¹',
        'Ø¡Ø§Ø±Ø´': 'Ø´Ø±Ø§Ø¡',
        'Ø¹ÙŠØ¨': 'Ø¨ÙŠØ¹',
        'Ø¶Ø±Ù‚': 'Ù‚Ø±Ø¶',
        'Ù„ÙŠÙˆÙ…Øª': 'ØªÙ…ÙˆÙŠÙ„',
        'Ù„Ø§ÙŠØ±': 'Ø±ÙŠØ§Ù„',
        'ÙŠØ¯ÙˆØ¹Ø³ Ù„Ø§ÙŠØ±': 'Ø±ÙŠØ§Ù„ Ø³Ø¹ÙˆØ¯ÙŠ',
        'ØºÙ„Ø¨Ù…': 'Ù…Ø¨Ù„Øº',
        'Ø¯ÙŠØµØ±': 'Ø±ØµÙŠØ¯',
        'Ø¨Ø§Ø³Ø­': 'Ø­Ø³Ø§Ø¨',
        'ÙŠØ±Ø§Ø¬ Ø¨Ø§Ø³Ø­': 'Ø­Ø³Ø§Ø¨ Ø¬Ø§Ø±ÙŠ',
        'Ø±Ø®Ø¯Ù… Ø¨Ø§Ø³Ø­': 'Ø­Ø³Ø§Ø¨ Ù…Ø¯Ø®Ø±',
        'Ø©Ù‚Ø§Ø·Ø¨': 'Ø¨Ø·Ø§Ù‚Ø©',
        'Ù†Ø§Ù…ØªØ¦Ø§ Ø©Ù‚Ø§Ø·Ø¨': 'Ø¨Ø·Ø§Ù‚Ø© Ø§Ø¦ØªÙ…Ø§Ù†',
        'ÙØ§Ø±Øµ': 'ØµØ±Ø§Ù',
        'ÙŠÙ„Ø¢ ÙØ§Ø±Øµ': 'ØµØ±Ø§Ù Ø¢Ù„ÙŠ',
        'Ù…ÙˆØ³Ø±': 'Ø±Ø³ÙˆÙ…',
        'Ø©Ø¨ÙŠØ±Ø¶': 'Ø¶Ø±ÙŠØ¨Ø©',
        'Ø©Ù…Ø¯Ø® Ù…ÙˆØ³Ø±': 'Ø±Ø³ÙˆÙ… Ø®Ø¯Ù…Ø©',
        'Ø©ÙØ§Ø¶Ù…Ù„Ø§ Ø©Ù…ÙŠÙ‚Ù„Ø§ Ø©Ø¨ÙŠØ±Ø¶': 'Ø¶Ø±ÙŠØ¨Ø© Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¶Ø§ÙØ©',
        'Ø®ÙŠØ±Ø§Øª': 'ØªØ§Ø±ÙŠØ®',
        'ÙØµÙˆ': 'ÙˆØµÙ',
        'Ø¹Ø¬Ø±Ù…': 'Ù…Ø±Ø¬Ø¹',
        'Ù…Ù‚Ø±': 'Ø±Ù‚Ù…',
        'Ø©Ø±ÙˆØªØ§Ù': 'ÙØ§ØªÙˆØ±Ø©',
        'Ù„Ø§ØµÙŠØ¥': 'Ø¥ÙŠØµØ§Ù„',
        'Ø¯Ù‚Ù†': 'Ù†Ù‚Ø¯',
        'ÙŠØ¯Ù‚Ù†': 'Ù†Ù‚Ø¯ÙŠ',
        'ÙƒÙŠØ´': 'Ø´ÙŠÙƒ',
    }
    
    for wrong, correct in banking_fixes.items():
        text = text.replace(wrong, correct)
    
    return text

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„ØªØµÙ†ÙŠÙ ====================

def clean_description(desc):
    """ØªÙ†Ø¸ÙŠÙ ÙˆØµÙ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©"""
    if not desc:
        return ""
    
    desc = fix_dots_text(desc)
    
    if desc in ["[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]", "[Ù…Ø­ØªÙˆÙ‰ Ù…Ø®ÙÙŠ]"]:
        return "Ø¹Ù…Ù„ÙŠØ© Ù…ØµØ±ÙÙŠØ©"
    
    desc = desc.strip()
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©
    desc = re.sub(r"MCC[:\-]?\d{4}", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"VAT\s*CHRG.*", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"Charges:.*", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"CITY[:\-]?.*?(?=\s|$)", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"MADA\s+\*{2,}\d+", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"CHNL:.*?DEP", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"Payment Systems.*?DEP", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"ID:\s*\d+", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"DEP\s+\d+", "", desc, flags=re.IGNORECASE)
    desc = re.sub(r"\*{4,}\d{4}", "", desc)
    desc = re.sub(r"\b\d{10,}\b", "", desc)
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
    desc = re.sub(r"\s{2,}", " ", desc)
    desc = desc.strip()
    
    if not desc or len(desc) < 3:
        return "Ø¹Ù…Ù„ÙŠØ© Ù…ØµØ±ÙÙŠØ©"
    
    return desc

def classify_expense_enhanced(desc, mcc=None, bank=None):
    """ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØµØ±ÙˆÙ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰"""
    if not desc:
        return "â“ ØºÙŠØ± Ù…ØµÙ†Ù"
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ ÙˆØ¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ø§Ø³ØªØ®Ø¯Ù… Ø¯Ø§Ù„Ø© Ø®Ø§ØµØ©
    if bank == 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ' and 'classify_alrajhi_transaction' in globals():
        main_category, sub_category = classify_alrajhi_transaction(desc)
    else:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ø§Ù…Ø©
        main_category, sub_category = classify_transaction(desc)
    
    # Ø¯Ù…Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙˆØ§Ù„ÙØ±Ø¹ÙŠ
    if sub_category != "ØºÙŠØ± Ù…Ø­Ø¯Ø¯":
        return f"{main_category} - {sub_category}"
    else:
        return main_category

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© ====================

def calculate_expense_percentages(expense_details):
    """Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨ Ø§Ù„Ù…ØµØ§Ø±ÙŠÙ"""
    total_expenses = sum(
        sum(trans['amount'] for trans in transactions)
        for transactions in expense_details.values()
    )
    
    percentages = {}
    for category, transactions in expense_details.items():
        category_total = sum(trans['amount'] for trans in transactions)
        percentages[category] = {
            'amount': category_total,
            'percentage': (category_total / total_expenses * 100) if total_expenses > 0 else 0,
            'count': len(transactions)
        }
    
    return percentages

def calculate_financial_metrics(income_details, expense_details):
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©"""
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØµØ§Ø±ÙŠÙ
    all_expenses = []
    for transactions in expense_details.values():
        all_expenses.extend([trans['amount'] for trans in transactions])
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø®Ù„
    all_incomes = [trans['amount'] for trans in income_details]
    
    metrics = {
        'avg_daily_expense': sum(all_expenses) / 30 if all_expenses else 0,
        'max_expense': max(all_expenses) if all_expenses else 0,
        'min_expense': min(all_expenses) if all_expenses else 0,
        'avg_income': sum(all_incomes) / len(all_incomes) if all_incomes else 0,
        'max_income': max(all_incomes) if all_incomes else 0,
        'min_income': min(all_incomes) if all_incomes else 0,
        'total_transactions': len(all_expenses) + len(all_incomes)
    }
    
    return metrics

def generate_insights(total_income, total_expenses, expense_details, financial_metrics):
    """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¤Ù‰ Ø°ÙƒÙŠØ© ÙˆØªÙˆØµÙŠØ§Øª ÙˆØ§Ù‚Ø¹ÙŠØ© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©"""
    insights = []
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    net_balance = total_income - total_expenses
    savings_rate = ((total_income - total_expenses) / total_income * 100) if total_income > 0 else 0
    expense_ratio = (total_expenses / total_income * 100) if total_income > 0 else 0
    daily_expense = financial_metrics.get('avg_daily_expense', 0)
    
    # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ø§Ù…
    if net_balance > 0:
        if savings_rate >= 20:
            insights.append({
                'title': 'ğŸ’° Ø£Ø¯Ø§Ø¡ Ù…Ø§Ù„ÙŠ Ù…Ù…ØªØ§Ø²',
                'description': f'Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø§Ø¯Ø®Ø§Ø± {savings_rate:.1f}% Ù…Ù† Ø¯Ø®Ù„Ùƒ - Ø£Ù†Øª ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­',
                'potential_saving': 0
            })
        elif savings_rate >= 10:
            insights.append({
                'title': 'ğŸ‘ Ø£Ø¯Ø§Ø¡ Ù…Ø§Ù„ÙŠ Ø¬ÙŠØ¯',
                'description': f'ØªØ¯Ø®Ø± {savings_rate:.1f}% Ù…Ù† Ø¯Ø®Ù„ÙƒØŒ Ø­Ø§ÙˆÙ„ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù€ 20%',
                'potential_saving': (total_income * 0.2) - (total_income - total_expenses)
            })
        else:
            insights.append({
                'title': 'âš ï¸ Ø§Ø¯Ø®Ø§Ø± Ù…Ù†Ø®ÙØ¶',
                'description': f'ØªØ¯Ø®Ø± ÙÙ‚Ø· {savings_rate:.1f}% Ù…Ù† Ø¯Ø®Ù„ÙƒØŒ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£Ù…Ø«Ù„ 20%',
                'potential_saving': (total_income * 0.2) - (total_income - total_expenses)
            })
    else:
        deficit = abs(net_balance)
        insights.append({
            'title': 'ğŸš¨ ØªØ­Ø°ÙŠØ±: Ù…ØµØ§Ø±ÙŠÙÙƒ ØªØªØ¬Ø§ÙˆØ² Ø¯Ø®Ù„Ùƒ',
            'description': f'Ø§Ù„Ø¹Ø¬Ø² Ø§Ù„Ø´Ù‡Ø±ÙŠ {deficit:,.0f} Ø±ÙŠØ§Ù„ - ÙŠØ¬Ø¨ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…ØµØ§Ø±ÙŠÙ ÙÙˆØ±Ø§Ù‹',
            'potential_saving': deficit
        })
    
    # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø¥Ù†ÙØ§Ù‚Ø§Ù‹
    if expense_details:
        # ØªØ±ØªÙŠØ¨ Ø§Ù„ÙØ¦Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¨Ù„Øº
        sorted_categories = sorted(
            [(cat, sum(t['amount'] for t in trans)) for cat, trans in expense_details.items()],
            key=lambda x: x[1],
            reverse=True
        )
        
        # Ø£ÙƒØ¨Ø± ÙØ¦Ø© Ø¥Ù†ÙØ§Ù‚
        if sorted_categories:
            top_category, top_amount = sorted_categories[0]
            top_percentage = (top_amount / total_expenses * 100)
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ù…Ù† Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ
            clean_category = re.sub(r'[^\w\s\-]', '', top_category).strip()
            
            if top_percentage > 30:
                insights.append({
                    'title': f'ğŸ“Š {clean_category} ÙŠØ³ØªÙ†Ø²Ù Ù…ÙŠØ²Ø§Ù†ÙŠØªÙƒ',
                    'description': f'Ù‡Ø°Ù‡ Ø§Ù„ÙØ¦Ø© ØªØ´ÙƒÙ„ {top_percentage:.0f}% Ù…Ù† Ù…ØµØ§Ø±ÙŠÙÙƒ ({top_amount:,.0f} Ø±ÙŠØ§Ù„) - Ø±Ø§Ø¬Ø¹ Ø¶Ø±ÙˆØ±Ø© ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ©',
                    'potential_saving': top_amount * 0.2  # ØªÙˆÙÙŠØ± 20% Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙØ¦Ø©
                })
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙØ¦Ø§Øª ÙŠÙ…ÙƒÙ† ØªÙ‚Ù„ÙŠÙ„Ù‡Ø§
            for category, amount in sorted_categories[1:4]:  # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ø¹Ù„Ù‰ 4 ÙØ¦Ø§Øª
                percentage = (amount / total_expenses * 100)
                clean_cat = re.sub(r'[^\w\s\-]', '', category).strip()
                
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªÙ‚Ù„ÙŠÙ„
                reducible_categories = ['Ù…Ø·Ø§Ø¹Ù…', 'ÙƒØ§ÙÙŠÙ‡Ø§Øª', 'ØªØ±ÙÙŠÙ‡', 'ØªØ³ÙˆÙ‚', 'Ù…Ù„Ø§Ø¨Ø³', 'Ø§Ø´ØªØ±Ø§ÙƒØ§Øª']
                if any(cat in clean_cat for cat in reducible_categories) and percentage > 15:
                    insights.append({
                        'title': f'ğŸ’¡ ÙØ±ØµØ© ØªÙˆÙÙŠØ± ÙÙŠ {clean_cat}',
                        'description': f'ØªÙ†ÙÙ‚ {percentage:.0f}% ({amount:,.0f} Ø±ÙŠØ§Ù„) - Ø¬Ø±Ø¨ ØªÙ‚Ù„ÙŠÙ„Ù‡Ø§ Ø¨Ù€ 30%',
                        'potential_saving': amount * 0.3
                    })
                    break
    
    # 3. ØªØ­Ù„ÙŠÙ„ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„ÙŠÙˆÙ…ÙŠ
    if daily_expense > 0:
        daily_income = total_income / 30
        daily_ratio = (daily_expense / daily_income * 100) if daily_income > 0 else 0
        
        if daily_ratio > 90:
            insights.append({
                'title': 'ğŸ“… Ø¥Ù†ÙØ§Ù‚Ùƒ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù…Ø±ØªÙØ¹ Ø¬Ø¯Ø§Ù‹',
                'description': f'ØªÙ†ÙÙ‚ {daily_expense:,.0f} Ø±ÙŠØ§Ù„ ÙŠÙˆÙ…ÙŠØ§Ù‹ ({daily_ratio:.0f}% Ù…Ù† Ø¯Ø®Ù„Ùƒ Ø§Ù„ÙŠÙˆÙ…ÙŠ) - Ø­Ø¯Ø¯ Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙŠÙˆÙ…ÙŠØ© ÙˆØ§Ø¶Ø­Ø©',
                'potential_saving': (daily_expense - (daily_income * 0.7)) * 30
            })
    
    # 4. ØªØ­Ù„ÙŠÙ„ Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
    total_transactions = sum(len(trans) for trans in expense_details.values())
    if total_transactions > 0:
        avg_transaction = total_expenses / total_transactions
        
        if total_transactions > 100:
            insights.append({
                'title': 'ğŸ”„ Ø¹Ø¯Ø¯ Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø±ØªÙØ¹',
                'description': f'{total_transactions} Ø¹Ù…Ù„ÙŠØ© Ø´Ù‡Ø±ÙŠØ§Ù‹ (Ù…ØªÙˆØ³Ø· {avg_transaction:,.0f} Ø±ÙŠØ§Ù„) - Ø­Ø§ÙˆÙ„ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª',
                'potential_saving': 0
            })
    
    # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©
    for category, transactions in expense_details.items():
        if 'ØªØ­ÙˆÙŠÙ„Ø§Øª' in category:
            transfer_amount = sum(t['amount'] for t in transactions)
            transfer_percentage = (transfer_amount / total_expenses * 100)
            
            if transfer_percentage > 40:
                insights.append({
                    'title': 'ğŸ”„ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ù…Ø±ØªÙØ¹Ø©',
                    'description': f'ØªØ´ÙƒÙ„ {transfer_percentage:.0f}% Ù…Ù† Ù…ØµØ§Ø±ÙŠÙÙƒ - ØªØ£ÙƒØ¯ Ù…Ù† Ø¶Ø±ÙˆØ±Ø© ÙƒÙ„ ØªØ­ÙˆÙŠÙ„',
                    'potential_saving': transfer_amount * 0.1
                })
                break
    
    # 6. Ù†ØµÙŠØ­Ø© Ø§Ù„Ø§Ø¯Ø®Ø§Ø± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
    if savings_rate < 10 and total_income > 0:
        recommended_savings = total_income * 0.1  # 10% Ù…Ù† Ø§Ù„Ø¯Ø®Ù„
        insights.append({
            'title': 'ğŸ’° Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø§Ø¯Ø®Ø§Ø± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ',
            'description': f'Ø®ØµØµ {recommended_savings:,.0f} Ø±ÙŠØ§Ù„ Ø´Ù‡Ø±ÙŠØ§Ù‹ (10% Ù…Ù† Ø¯Ø®Ù„Ùƒ) Ù„Ù„Ø§Ø¯Ø®Ø§Ø± ÙˆØ§Ø¬Ø¹Ù„Ù‡ ØªØ­ÙˆÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ',
            'potential_saving': 0
        })
    
    # 7. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ù†ÙØ§Ù‚ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
    for category, transactions in expense_details.items():
        if len(transactions) >= 10:  # ÙØ¦Ø§Øª Ø¨Ø¹Ù…Ù„ÙŠØ§Øª Ù…ØªÙƒØ±Ø±Ø©
            clean_cat = re.sub(r'[^\w\s\-]', '', category).strip()
            category_amount = sum(t['amount'] for t in transactions)
            avg_per_transaction = category_amount / len(transactions)
            
            if 'Ù‚Ù‡ÙˆØ©' in clean_cat or 'ÙƒØ§ÙÙŠ' in clean_cat:
                daily_coffee = len(transactions) / 30
                if daily_coffee > 0.5:  # Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ø±Ø© ÙƒÙ„ ÙŠÙˆÙ…ÙŠÙ†
                    monthly_coffee_cost = category_amount
                    insights.append({
                        'title': 'â˜• Ø¹Ø§Ø¯Ø© Ø§Ù„Ù‚Ù‡ÙˆØ© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©',
                        'description': f'ØªØ´Ø±Ø¨ Ù‚Ù‡ÙˆØ© {daily_coffee:.1f} Ù…Ø±Ø© ÙŠÙˆÙ…ÙŠØ§Ù‹ Ø¨ØªÙƒÙ„ÙØ© {monthly_coffee_cost:,.0f} Ø±ÙŠØ§Ù„ Ø´Ù‡Ø±ÙŠØ§Ù‹ - Ø¬Ø±Ø¨ ØªÙ‚Ù„ÙŠÙ„Ù‡Ø§ Ù„Ù„Ù†ØµÙ',
                        'potential_saving': monthly_coffee_cost * 0.5
                    })
                    break
    
    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø±Ø¤Ù‰ Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
    insights.sort(key=lambda x: x.get('potential_saving', 0), reverse=True)
    
    # Ø¥Ø±Ø¬Ø§Ø¹ Ø£Ù‡Ù… 5 Ø±Ø¤Ù‰ ÙÙ‚Ø·
    return insights[:5]

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ====================

def detect_bank_type(pdf_path):
    """ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ PDF"""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            # ÙØ­Øµ Ø£ÙˆÙ„ 3 ØµÙØ­Ø§Øª Ù„Ù„ØªØ£ÙƒØ¯
            pages_to_check = min(3, len(pdf.pages))
            combined_text = ""
            
            for i in range(pages_to_check):
                page_text = pdf.pages[i].extract_text() or ""
                combined_text += page_text + " "
            
            combined_text_lower = combined_text.lower()
            
            # ØªØ­Ø³ÙŠÙ† ÙƒØ´Ù Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ - Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©
            rajhi_indicators = [
                'alrajhibank.com', 'alrajhibank.com.sa',  # Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø±Ø³Ù…ÙŠ
                'alrajhi bank', 'Ù…ØµØ±Ù Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ',
                '920 003 344',  # Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ Ø§Ù„Ù…Ù…ÙŠØ² Ù„Ù„Ø±Ø§Ø¬Ø­ÙŠ
                'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ', 'alrajhi', 'al rajhi', 'al-rajhi',
                'Ù…ØµØ±Ù Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ', 'al rajhi bank', 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ø§Ù„Ù…ØµØ±ÙÙŠØ©',
                'alrajhi banking', 'Ù…ØµØ±Ù Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ø§Ù„Ù…ØµØ±ÙÙŠØ©',
                'al rajhi banking', 'Ø´Ø±ÙƒØ© Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ø§Ù„Ù…ØµØ±ÙÙŠØ©',
                'rajhi', 'Ø§Ù„Ø±Ø§Ø¬Ø­Ù‰', 'al-rajhi bank',
                'Ù…ØµØ±Ù Ø§Ù„Ø±Ø§Ø¬Ø­Ù‰', 'alrajhi bank',
                # Ø¥Ø¶Ø§ÙØ© Ø£Ø±Ù‚Ø§Ù… ÙˆØ£ÙƒÙˆØ§Ø¯ Ø®Ø§ØµØ© Ø¨Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ
                '80000', 'rjhi', 'sarb', 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±',
                'al rajhi capital', 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ ÙƒØ§Ø¨ÙŠØªØ§Ù„'
            ]
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ
            for indicator in rajhi_indicators:
                if indicator in combined_text_lower:
                    app.logger.info(f"âœ… ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø©: {indicator}")
                    return 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ'
            
            # ÙƒØ´Ù Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ
            ahli_indicators = [
                'Ø§Ù„Ø£Ù‡Ù„ÙŠ', 'Ø§Ù„Ø§Ù‡Ù„ÙŠ', 'ahli', 'al ahli', 'Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ',
                'Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø§Ù‡Ù„ÙŠ', 'national bank', 'snb', 'Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ',
                'Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ', 'saudi national bank',
                'Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø§Ù‡Ù„ÙŠ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ', 'ncb', 'Ø§Ù„Ø§Ù‡Ù„ÙŠ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ'
            ]
            
            for indicator in ahli_indicators:
                if indicator in combined_text_lower:
                    app.logger.info(f"âœ… ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø¨ÙˆØ§Ø³Ø·Ø©: {indicator}")
                    return 'Ø§Ù„Ø£Ù‡Ù„ÙŠ'
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø®Ø§ØµØ© ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙƒØ´Ù
            # Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ ÙŠØ³ØªØ®Ø¯Ù… Ø¬Ø¯ÙˆÙ„ Ø¨ØªÙ†Ø³ÙŠÙ‚: Ø§Ù„ØªØ§Ø±ÙŠØ® | ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© | Ù…Ø¯ÙŠÙ† | Ø¯Ø§Ø¦Ù† | Ø§Ù„Ø±ØµÙŠØ¯
            if 'ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©' in combined_text and 'Ù…Ø¯ÙŠÙ†' in combined_text and 'Ø¯Ø§Ø¦Ù†' in combined_text and 'Ø§Ù„Ø±ØµÙŠØ¯' in combined_text:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ "Statement Details" Ùˆ "ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ´Ù" Ù…Ø¹Ø§Ù‹ (Ø®Ø§Øµ Ø¨Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ)
                if 'statement details' in combined_text_lower and 'ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ´Ù' in combined_text:
                    app.logger.info("âœ… ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ù…Ù† Ø®Ù„Ø§Ù„ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙƒØ´Ù Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù„ØºØ©")
                    return 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ'
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®Ø±Ù‰: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø®Ø§ØµØ© Ø¨ÙƒÙ„ Ø¨Ù†Ùƒ ÙÙŠ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            for page in pdf.pages[:pages_to_check]:
                tables = page.extract_tables()
                for table in tables:
                    if not table:
                        continue
                    
                    # ÙØ­Øµ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„
                    if len(table) > 0:
                        header_row = ' '.join(str(cell) for cell in table[0] if cell).lower()
                        
                        # Ù†Ù…Ø· Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ: Ø§Ù„ØªØ§Ø±ÙŠØ® | ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© | Ù…Ø¯ÙŠÙ† | Ø¯Ø§Ø¦Ù† | Ø§Ù„Ø±ØµÙŠØ¯
                        if all(word in header_row for word in ['ØªØ§Ø±ÙŠØ®', 'ØªÙØ§ØµÙŠÙ„', 'Ù…Ø¯ÙŠÙ†', 'Ø¯Ø§Ø¦Ù†', 'Ø±ØµÙŠØ¯']):
                            app.logger.info("âœ… ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ù…Ù† Ø®Ù„Ø§Ù„ ØªÙ†Ø³ÙŠÙ‚ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„")
                            return 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ'
                        
                        # Ù†Ù…Ø· Ø§Ù„Ø£Ù‡Ù„ÙŠ: ÙŠØ®ØªÙ„Ù Ø¹Ù† Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ
                        if 'transaction' in header_row and 'description' in header_row:
                            app.logger.info("âœ… ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ Ù…Ù† Ø®Ù„Ø§Ù„ ØªÙ†Ø³ÙŠÙ‚ Ø±Ø£Ø³ Ø§Ù„Ø¬Ø¯ÙˆÙ„")
                            return 'Ø§Ù„Ø£Ù‡Ù„ÙŠ'
                
    except Exception as e:
        app.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ: {str(e)}")
    
    app.logger.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ")
    return 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'


def extract_transaction_from_line(line):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø© Ù…Ù† Ø³Ø·Ø± Ù†ØµÙŠ"""
    date_pattern = r'(\d{1,2}[-/]\d{1,2}[-/]\d{2,4})'
    amount_pattern = r'([\d,]+\.?\d*)'
    
    date_match = re.search(date_pattern, line)
    amount_matches = re.findall(amount_pattern, line)
    
    if date_match and amount_matches:
        date = date_match.group(1)
        amount = amount_matches[-1].replace(',', '')
        
        desc_start = date_match.end()
        desc_end = line.rfind(amount_matches[-1])
        
        if desc_end > desc_start:
            desc = line[desc_start:desc_end].strip()
            return [date, desc, amount]
    
    return None

def extract_with_pymupdf(pdf_path):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyMuPDF"""
    if not PYMUPDF_AVAILABLE:
        return None
    
    try:
        doc = fitz.open(pdf_path)
        all_data = []
        
        # ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ
        bank_type = detect_bank_type(pdf_path)
        app.logger.info(f"ğŸ¦ PyMuPDF: Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ = {bank_type}")
        
        for page_num in range(len(doc)):
            page = doc[page_num]
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            tables = page.find_tables()
            
            if tables:
                for table in tables:
                    table_data = table.extract()
                    
                    # ØªØ®Ø·ÙŠ Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ù†Ø§ÙˆÙŠÙ†
                    start_row = 0
                    if table_data and len(table_data) > 0:
                        first_row_text = ' '.join(str(cell) for cell in table_data[0] if cell).lower()
                        if any(header in first_row_text for header in ['ØªØ§Ø±ÙŠØ®', 'date', 'Ù…Ø¯ÙŠÙ†', 'Ø¯Ø§Ø¦Ù†', 'Ø§Ù„Ø±ØµÙŠØ¯', 'ØªÙØ§ØµÙŠÙ„']):
                            start_row = 1
                    
                    for row_idx in range(start_row, len(table_data)):
                        row = table_data[row_idx]
                        if not row or len(row) < 4:
                            continue
                        
                        if bank_type == 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ':
                            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„Ø±Ø§Ø¬Ø­ÙŠ
                            transaction = extract_alrajhi_transaction(row)
                            if transaction:
                                all_data.append({
                                    'date': transaction['date'],
                                    'desc': transaction['desc'],
                                    'amount': transaction['amount'],
                                    'type': transaction['type']
                                })
                        else:
                            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù„Ø¨Ù†ÙˆÙƒ Ø§Ù„Ø£Ø®Ø±Ù‰
                            if len(row) >= 3:
                                all_data.append({
                                    'date': fix_arabic_text_advanced(str(row[0])),
                                    'desc': fix_arabic_text_advanced(str(row[1])),
                                    'amount': str(row[2]) if len(row) > 2 else ''
                                })
            else:
                # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ø¬Ø¯Ø§ÙˆÙ„ØŒ Ø§Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„Ù†Øµ
                text = page.get_text()
                lines = text.split('\n')
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ
                in_transaction_section = False
                
                for i, line in enumerate(lines):
                    line = line.strip()
                    if not line:
                        continue
                    
                    # Ø¨Ø¯Ø§ÙŠØ© Ù‚Ø³Ù… Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
                    if 'Ø§Ù„ØªØ§Ø±ÙŠØ®' in line and 'ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©' in line:
                        in_transaction_section = True
                        continue
                    
                    if in_transaction_section:
                        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ø³Ø·Ø±
                        # Ù†Ù…Ø· Ø§Ù„ØªØ§Ø±ÙŠØ®
                        date_match = re.search(r'(\d{4}/\d{2}/\d{2})', line)
                        if date_match:
                            # Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©
                            transaction_lines = [line]
                            
                            # Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ØªØ§Ù„ÙŠØ© Ø­ØªÙ‰ Ù†Ø¬Ø¯ ØªØ§Ø±ÙŠØ® Ø¬Ø¯ÙŠØ¯ Ø£Ùˆ Ù†Ù‡Ø§ÙŠØ©
                            j = i + 1
                            while j < len(lines) and not re.search(r'^\d{4}/\d{2}/\d{2}', lines[j]):
                                if lines[j].strip():
                                    transaction_lines.append(lines[j].strip())
                                j += 1
                                if j - i > 5:  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 5 Ø£Ø³Ø·Ø± Ù„Ù„Ù…Ø¹Ø§Ù…Ù„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø©
                                    break
                            
                            # Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø³Ø·Ø±
                            full_transaction = ' '.join(transaction_lines)
                            
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¨Ù„Øº
                            amount_match = re.search(r'([\d,]+\.?\d*)\s*SAR', full_transaction)
                            if amount_match:
                                try:
                                    amount_str = amount_match.group(1).replace(',', '')
                                    amount = float(amount_str)
                                    
                                    # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø©
                                    if 'Ø¯Ø§Ø¦Ù†' in full_transaction or 'Ø­ÙˆØ§Ù„Ø© ÙˆØ§Ø±Ø¯Ø©' in full_transaction:
                                        transaction_type = 'income'
                                    else:
                                        transaction_type = 'expense'
                                        amount = -amount
                                    
                                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙØ§ØµÙŠÙ„
                                    desc_start = full_transaction.find('SAR') + 3
                                    desc = full_transaction[desc_start:].strip()
                                    
                                    if not desc:
                                        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ù…ÙƒØ§Ù† Ø¢Ø®Ø±
                                        desc_parts = full_transaction.split('SAR')
                                        if len(desc_parts) > 1:
                                            desc = desc_parts[-1].strip()
                                    
                                    all_data.append({
                                        'date': date_match.group(1),
                                        'desc': fix_arabic_text_advanced(desc) if desc else "Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†ÙƒÙŠØ©",
                                        'amount': amount,
                                        'type': transaction_type
                                    })
                                except:
                                    continue
        
        doc.close()
        
        app.logger.info(f"âœ… PyMuPDF: ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(all_data)} Ù…Ø¹Ø§Ù…Ù„Ø©")
        return all_data
        
    except Exception as e:
        app.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ PyMuPDF: {str(e)}")
        return None
    
def extract_alrajhi_transaction(row, page_text=None):
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø© Ù…Ù† ÙƒØ´Ù Ø­Ø³Ø§Ø¨ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ
    Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: ØªØ§Ø±ÙŠØ® | ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© | Ù…Ø¯ÙŠÙ† | Ø¯Ø§Ø¦Ù† | Ø§Ù„Ø±ØµÙŠØ¯
    Ø£Ùˆ: ØªØ§Ø±ÙŠØ® | Ù…Ø¯ÙŠÙ† | Ø¯Ø§Ø¦Ù† | Ø§Ù„Ø±ØµÙŠØ¯ | ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
    """
    if not row or len(row) < 4:
        return None
    
    try:
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
        cleaned_row = []
        for cell in row:
            cleaned = extract_text_properly(cell)
            if cleaned and cleaned != "[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]":
                cleaned_row.append(cleaned)
            else:
                cleaned_row.append("")
        
        # Ø¥Ø¶Ø§ÙØ© Ø®Ù„Ø§ÙŠØ§ ÙØ§Ø±ØºØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ø¯Ø¯ Ø£Ù‚Ù„ Ù…Ù† 5
        while len(cleaned_row) < 5:
            cleaned_row.append("")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø°ÙƒØ§Ø¡
        date_idx = -1
        details_idx = -1
        debit_idx = -1
        credit_idx = -1
        balance_idx = -1
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø¹Ø§Ø¯Ø© ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„)
        for i, cell in enumerate(cleaned_row):
            if re.search(r'\d{1,2}[-/]\d{1,2}[-/]\d{2,4}', cell):
                date_idx = i
                break
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¨Ø§Ù„Øº (ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ùˆ SAR Ø£Ùˆ Ø±ÙŠØ§Ù„)
        amount_indices = []
        for i, cell in enumerate(cleaned_row):
            if i != date_idx and re.search(r'[\d,]+\.?\d*\s*(SAR|Ø±ÙŠØ§Ù„|ï·¼)?', cell):
                amount_indices.append(i)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø£Ù…Ø§ÙƒÙ† Ø§Ù„Ù…Ø¨Ø§Ù„Øº
        if len(amount_indices) >= 3:
            # Ù†ÙØªØ±Ø¶: Ù…Ø¯ÙŠÙ†ØŒ Ø¯Ø§Ø¦Ù†ØŒ Ø±ØµÙŠØ¯
            debit_idx = amount_indices[0]
            credit_idx = amount_indices[1]
            balance_idx = amount_indices[2]
        elif len(amount_indices) == 2:
            # Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø£Ø­Ø¯ Ø§Ù„Ø­Ù‚ÙˆÙ„ ÙØ§Ø±Øº
            debit_idx = amount_indices[0]
            credit_idx = amount_indices[1]
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ (Ø¹Ø§Ø¯Ø© Ø£Ø·ÙˆÙ„ Ù†Øµ ÙˆÙ„ÙŠØ³ Ø±Ù‚Ù…)
        max_len = 0
        for i, cell in enumerate(cleaned_row):
            if i not in [date_idx, debit_idx, credit_idx, balance_idx]:
                if len(cell) > max_len and not re.match(r'^[\d\s,.-]+$', cell):
                    max_len = len(cell)
                    details_idx = i
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŒ Ù†Ø¨Ø­Ø« ÙÙŠ Ø¢Ø®Ø± Ø¹Ù…ÙˆØ¯
        if details_idx == -1 and len(cleaned_row) >= 5:
            for i in [4, 1]:  # Ø¬Ø±Ø¨ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø®Ø§Ù…Ø³ Ø«Ù… Ø§Ù„Ø«Ø§Ù†ÙŠ
                if i not in [debit_idx, credit_idx, balance_idx] and cleaned_row[i]:
                    details_idx = i
                    break
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        date = cleaned_row[date_idx] if date_idx >= 0 else ""
        details = cleaned_row[details_idx] if details_idx >= 0 else ""
        debit = cleaned_row[debit_idx] if debit_idx >= 0 else ""
        credit = cleaned_row[credit_idx] if credit_idx >= 0 else ""
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¨Ù„Øº
        amount = 0.0
        transaction_type = None
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ù…Ø¯ÙŠÙ† (Ù…ØµØ±ÙˆÙ)
        if debit and debit not in ["0.00", "0.00 SAR", "0", "-"]:
            amount_str = re.sub(r'[^\d\.-]', '', debit)
            amount_str = amount_str.replace(',', '')
            try:
                amount_val = float(amount_str)
                if amount_val > 0:
                    amount = -amount_val  # Ø³Ø§Ù„Ø¨ Ù„Ù„Ù…ØµØ±ÙˆÙØ§Øª
                    transaction_type = "expense"
            except:
                pass
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ø¯Ø§Ø¦Ù† (Ø¯Ø®Ù„)
        if credit and credit not in ["0.00", "0.00 SAR", "0", "-"]:
            amount_str = re.sub(r'[^\d\.-]', '', credit)
            amount_str = amount_str.replace(',', '')
            try:
                amount_val = float(amount_str)
                if amount_val > 0:
                    amount = amount_val  # Ù…ÙˆØ¬Ø¨ Ù„Ù„Ø¯Ø®Ù„
                    transaction_type = "income"
            except:
                pass
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ù…Ø¨Ù„ØºØŒ Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø§Ù„Ø®Ù„Ø§ÙŠØ§
        if amount == 0:
            for i, cell in enumerate(cleaned_row):
                if i != date_idx and i != details_idx:
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…Ø· Ø§Ù„Ù…Ø¨Ù„Øº
                    match = re.search(r'([\d,]+\.?\d*)\s*(SAR|Ø±ÙŠØ§Ù„|ï·¼)?', cell)
                    if match:
                        amount_str = match.group(1).replace(',', '')
                        try:
                            amount_val = float(amount_str)
                            if amount_val > 0 and amount_val != 100000:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                                # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
                                if any(word in str(row).lower() for word in ['Ø³Ø­Ø¨', 'Ø´Ø±Ø§Ø¡', 'Ø¯ÙØ¹', 'withdrawal', 'purchase']):
                                    amount = -amount_val
                                    transaction_type = "expense"
                                else:
                                    amount = amount_val
                                    transaction_type = "income"
                                break
                        except:
                            pass
        
        # Ø¥Ø°Ø§ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¨Ù„Øº ØµØ§Ù„Ø­
        if amount != 0:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªØ§Ø±ÙŠØ®
            if not date or date == "[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]":
                date = datetime.now().strftime("%d/%m/%Y")
            else:
                date = fix_arabic_text_advanced(date)
            
            # ØªÙ†Ø¸ÙŠÙ ÙˆØ¥ØµÙ„Ø§Ø­ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
            if not details or details == "[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]":
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„ØªÙØ§ØµÙŠÙ„ ÙÙŠ Ø£ÙŠ Ø®Ù„ÙŠØ©
                for cell in cleaned_row:
                    if cell and len(cell) > 10 and not re.match(r'^[\d\s,.-]+$', cell) and cell != date:
                        details = cell
                        break
                
                if not details:
                    details = "Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†ÙƒÙŠØ© - Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ"
            
            details = deep_fix_arabic_text(details)
            
            # ØªØ³Ø¬ÙŠÙ„ Ù„Ù„ØªØªØ¨Ø¹
            app.logger.info(f"âœ… Ù…Ø¹Ø§Ù…Ù„Ø© Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ: Ø§Ù„ØªØ§Ø±ÙŠØ®={date}, Ø§Ù„Ù…Ø¨Ù„Øº={amount}, Ø§Ù„Ù†ÙˆØ¹={transaction_type}, Ø§Ù„ØªÙØ§ØµÙŠÙ„={details[:50]}...")
            
            return {
                'date': date,
                'desc': details,
                'amount': amount,
                'type': transaction_type,
                'bank': 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ'
            }
        else:
            app.logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¨Ù„Øº ØµØ§Ù„Ø­ ÙÙŠ Ø§Ù„ØµÙ: {cleaned_row}")
    
    except Exception as e:
        app.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø© Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ: {str(e)}")
        app.logger.error(f"   Ø§Ù„ØµÙ: {row}")
    
    return None


def extract_alrajhi_transaction_from_data(item):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø© Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ø¨ÙˆØ§Ø³Ø·Ø© PyMuPDF"""
    if isinstance(item, dict):
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø§Ù‡Ø²Ø© Ø¨Ø§Ù„ÙØ¹Ù„
        if all(key in item for key in ['date', 'desc', 'amount']):
            try:
                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø¨Ù„Øº Ø±Ù‚Ù…
                if isinstance(item['amount'], (int, float)):
                    amount = float(item['amount'])
                else:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø±Ù‚Ù…
                    amount_str = re.sub(r'[^\d\.-]', '', str(item['amount']))
                    amount = float(amount_str) if amount_str else 0
                
                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯
                if 'type' not in item:
                    item['type'] = 'income' if amount > 0 else 'expense'
                
                return {
                    'date': item['date'],
                    'desc': item['desc'],
                    'amount': amount,
                    'type': item['type'],
                    'bank': 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ'
                }
            except Exception as e:
                app.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
                return None
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù‚Ø§Ø¦Ù…Ø©
    elif isinstance(item, (list, tuple)):
        return extract_alrajhi_transaction(list(item))
    
    return None

def process_transaction(date, desc, amount, income_details, expense_details):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¹Ø§Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©"""
    if amount > 0:
        # Ø¯Ø®Ù„
        income_details.append({
            "date": date, 
            "desc": desc, 
            "amount": amount
        })
    else:
        # Ù…ØµØ±ÙˆÙ
        abs_amt = abs(amount)
        category = classify_expense_enhanced(desc)
        expense_details[category].append({
            "date": date, 
            "desc": desc, 
            "amount": abs_amt
        })

def analyze_transactions(pdf_path):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ù† Ù…Ù„Ù PDF ÙˆØ§Ø­Ø¯ - ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ ÙˆØ§Ù„Ø±Ø§Ø¬Ø­ÙŠ"""
    income_count = 0
    expense_count = 0
    total_income = 0.0
    total_expense = 0.0
    skipped_rows = 0
    total_rows = 0
    income_details = []
    expense_details = defaultdict(list)
    
    app.logger.info("ğŸ” Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø­Ø³Ø§Ø¨...")
    
    # ÙƒØ´Ù Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ
    bank_type = detect_bank_type(pdf_path)
    app.logger.info(f"ğŸ¦ Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ù…ÙƒØªØ´Ù: {bank_type}")

    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… PyMuPDF Ø£ÙˆÙ„Ø§Ù‹
    if PYMUPDF_AVAILABLE:
        app.logger.info("ğŸ“˜ Ø§Ø³ØªØ®Ø¯Ø§Ù… PyMuPDF Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ...")
        extracted_data = extract_with_pymupdf(pdf_path)
        
        if extracted_data:
            for item in extracted_data:
                total_rows += 1
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø¨Ù†Ùƒ
                if bank_type == 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ':
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø§Ù…Ù„Ø© Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ
                    transaction = extract_alrajhi_transaction_from_data(item)
                    if transaction:
                        if transaction['type'] == 'income':
                            income_count += 1
                            total_income += abs(transaction['amount'])
                            income_details.append({
                                "date": transaction['date'],
                                "desc": transaction['desc'],
                                "amount": abs(transaction['amount'])
                            })
                        elif transaction['type'] == 'expense':
                            expense_count += 1
                            abs_amt = abs(transaction['amount'])
                            total_expense += abs_amt
                            
                            category = classify_expense_enhanced(transaction['desc'], bank=bank_type)
                            expense_details[category].append({
                                "date": transaction['date'],
                                "desc": transaction['desc'],
                                "amount": abs_amt
                            })
                    else:
                        skipped_rows += 1
                else:
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ (Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©)
                    try:
                        amount = float(re.sub(r"[^\d\.-]", "", str(item['amount'])))
                    except:
                        skipped_rows += 1
                        continue
                    
                    date = item['date']
                    desc = item['desc']
                    
                    if not desc or desc == "[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]":
                        desc = "Ø¹Ù…Ù„ÙŠØ© Ù…ØµØ±ÙÙŠØ©"
                    
                    if amount > 0:
                        if any(x in desc.lower() for x in ["Ø¶Ø±ÙŠØ¨Ø©", "Ø±Ø³ÙˆÙ…", "vat", "fee", "charge"]):
                            skipped_rows += 1
                            continue
                        income_count += 1
                        total_income += amount
                        income_details.append({"date": date, "desc": desc, "amount": amount})
                    elif amount < 0:
                        expense_count += 1
                        abs_amt = abs(amount)
                        total_expense += abs_amt
                        
                        category = classify_expense_enhanced(desc)
                        expense_details[category].append({"date": date, "desc": desc, "amount": abs_amt})
                    else:
                        skipped_rows += 1
            
            total_count = income_count + expense_count
            app.logger.info(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ {total_count} Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
            return total_rows, total_count, income_count, total_income, expense_count, total_expense, skipped_rows, income_details, expense_details

    # Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ pdfplumber
    app.logger.info("ğŸ“„ Ø§Ø³ØªØ®Ø¯Ø§Ù… pdfplumber...")
    
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            tables = page.extract_tables({
                "vertical_strategy": "lines",
                "horizontal_strategy": "lines",
                "snap_tolerance": 3,
                "join_tolerance": 3,
                "edge_min_length": 50,
                "min_words_vertical": 0,
                "min_words_horizontal": 0,
                "text_tolerance": 3,
                "text_x_tolerance": 3,
                "text_y_tolerance": 3,
                "intersection_tolerance": 3,
            })
            
            if not tables:
                text = page.extract_text()
                if text:
                    lines = text.split('\n')
                    for line in lines:
                        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ Ù…Ù† Ø§Ù„Ù†Øµ
                        if bank_type != 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ':
                            parts = extract_transaction_from_line(line)
                            if parts:
                                total_rows += 1
                                date = deep_fix_arabic_text(parts[0])
                                desc = deep_fix_arabic_text(parts[1])
                                try:
                                    amount = float(parts[2])
                                    process_transaction(date, desc, amount, income_details, expense_details)
                                    if amount > 0:
                                        income_count += 1
                                        total_income += amount
                                    else:
                                        expense_count += 1
                                        total_expense += abs(amount)
                                except:
                                    skipped_rows += 1
                continue
            
            for table in tables:
                # ØªØ®Ø·ÙŠ Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ (Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†)
                for row in table[1:]:
                    total_rows += 1
                    
                    if bank_type == 'Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ':
                        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ
                        transaction = extract_alrajhi_transaction(row)
                        if transaction:
                            if transaction['type'] == 'income':
                                income_count += 1
                                total_income += abs(transaction['amount'])
                                income_details.append({
                                    "date": transaction['date'],
                                    "desc": transaction['desc'],
                                    "amount": abs(transaction['amount'])
                                })
                            elif transaction['type'] == 'expense':
                                expense_count += 1
                                abs_amt = abs(transaction['amount'])
                                total_expense += abs_amt
                                
                                category = classify_expense_enhanced(transaction['desc'], bank=bank_type)
                                expense_details[category].append({
                                    "date": transaction['date'],
                                    "desc": transaction['desc'],
                                    "amount": abs_amt
                                })
                        else:
                            skipped_rows += 1
                    
                    else:
                        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ (Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©)
                        if len(row) < 3 or not row[2]:
                            skipped_rows += 1
                            continue
                        
                        date_raw = extract_text_properly(row[0])
                        desc_raw = extract_text_properly(row[1])
                        amount_raw = extract_text_properly(row[2])
                        
                        date = deep_fix_arabic_text(date_raw)
                        desc = deep_fix_arabic_text(desc_raw)
                        
                        if not date or date == "[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]":
                            date = datetime.now().strftime("%d/%m/%Y")
                        
                        if not desc or desc == "[Ù†Øµ ØºÙŠØ± Ù…Ù‚Ø±ÙˆØ¡]":
                            desc = "Ø¹Ù…Ù„ÙŠØ© Ù…ØµØ±ÙÙŠØ©"
                        
                        try:
                            amount = float(re.sub(r"[^\d\.-]", "", amount_raw))
                        except:
                            skipped_rows += 1
                            continue

                        if amount > 0:
                            if any(x in desc.lower() for x in ["Ø¶Ø±ÙŠØ¨Ø©", "Ø±Ø³ÙˆÙ…", "vat", "fee", "charge"]):
                                skipped_rows += 1
                                continue
                            income_count += 1
                            total_income += amount
                            income_details.append({"date": date, "desc": desc, "amount": amount})
                        elif amount < 0:
                            expense_count += 1
                            abs_amt = abs(amount)
                            total_expense += abs_amt
                            
                            category = classify_expense_enhanced(desc)
                            expense_details[category].append({"date": date, "desc": desc, "amount": abs_amt})
                        else:
                            skipped_rows += 1

    total_count = income_count + expense_count
    
    if skipped_rows > total_rows * 0.3:
        app.logger.warning(f"âš ï¸ ØªØ­Ø°ÙŠØ±: {skipped_rows} Ù…Ù† {total_rows} ØµÙ Ù„Ù… ÙŠØªÙ… Ù‚Ø±Ø§Ø¡ØªÙ‡Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­")
        app.logger.info("ğŸ’¡ Ù†ØµÙŠØ­Ø©: Ø¬Ø±Ù‘Ø¨ ØªØ«Ø¨ÙŠØª PyMuPDF Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„: pip install PyMuPDF")
    
    app.logger.info(f"ğŸ¦ ØªÙ… ØªØ­Ù„ÙŠÙ„ ÙƒØ´Ù Ø­Ø³Ø§Ø¨ {bank_type}")
    app.logger.info(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª: {total_count}")
    app.logger.info(f"ğŸ“ˆ Ø§Ù„Ø¯Ø®Ù„: {income_count} Ø¹Ù…Ù„ÙŠØ© - {total_income:,.2f} Ø±ÙŠØ§Ù„")
    app.logger.info(f"ğŸ“‰ Ø§Ù„Ù…ØµØ§Ø±ÙŠÙ: {expense_count} Ø¹Ù…Ù„ÙŠØ© - {total_expense:,.2f} Ø±ÙŠØ§Ù„")
    
    return total_rows, total_count, income_count, total_income, expense_count, total_expense, skipped_rows, income_details, expense_details

def analyze_multiple_transactions(pdf_files):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ù† Ù…Ù„ÙØ§Øª PDF Ù…ØªØ¹Ø¯Ø¯Ø©"""
    total_income_count = 0
    total_expense_count = 0
    total_income_sum = 0.0
    total_expense_sum = 0.0
    total_skipped_rows = 0
    total_rows_processed = 0
    
    combined_income_details = []
    combined_expense_details = defaultdict(list)
    
    app.logger.info(f"\nğŸ“Š Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ {len(pdf_files)} Ù…Ù„Ù(Ø§Øª)...")
    
    for i, pdf_path in enumerate(pdf_files, 1):
        app.logger.info(f"\nğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù {i}: {os.path.basename(pdf_path)}")
        
        try:
            (rows, ops, inc_count, inc_sum, exp_count, exp_sum, skipped, 
             income_details, expense_details) = analyze_transactions(pdf_path)
            
            total_income_count += inc_count
            total_expense_count += exp_count
            total_income_sum += inc_sum
            total_expense_sum += exp_sum
            total_skipped_rows += skipped
            total_rows_processed += rows
            
            for income_item in income_details:
                income_item['account_file'] = os.path.basename(pdf_path)
                combined_income_details.append(income_item)
            
            for category, transactions in expense_details.items():
                for transaction in transactions:
                    transaction['account_file'] = os.path.basename(pdf_path)
                    combined_expense_details[category].append(transaction)
            
            app.logger.info(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù {i} Ø¨Ù†Ø¬Ø§Ø­")
            app.logger.info(f"   ğŸ“ˆ Ø¯Ø®Ù„: {inc_count} Ø¹Ù…Ù„ÙŠØ© - {inc_sum:,.2f} Ø±ÙŠØ§Ù„")
            app.logger.info(f"   ğŸ“‰ Ù…ØµØ§Ø±ÙŠÙ: {exp_count} Ø¹Ù…Ù„ÙŠØ© - {exp_sum:,.2f} Ø±ÙŠØ§Ù„")
            
        except Exception as e:
            app.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù {i}: {str(e)}")
            continue
    
    total_operations = total_income_count + total_expense_count
    
    app.logger.info(f"\nğŸ¯ Ø§Ù†ØªÙ‡Ù‰ ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª!")
    app.logger.info(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª: {total_operations}")
    app.logger.info(f"ğŸ’° Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¯Ø®Ù„: {total_income_sum:,.2f} Ø±ÙŠØ§Ù„")
    app.logger.info(f"ğŸ’¸ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØµØ§Ø±ÙŠÙ: {total_expense_sum:,.2f} Ø±ÙŠØ§Ù„")
    
    return (total_rows_processed, total_operations, total_income_count, total_income_sum,
            total_expense_count, total_expense_sum, total_skipped_rows, 
            combined_income_details, combined_expense_details)

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ====================

def init_db():
    """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ø£ÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£ÙˆÙ„ÙŠØ©"""
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ templates Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯
    if not os.path.exists('templates'):
        os.makedirs('templates')
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
    if not os.path.exists(app.config['UPLOAD_FOLDER']):
        os.makedirs(app.config['UPLOAD_FOLDER'])
    
    app.logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ù†Ø¬Ø§Ø­")

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def delete_files_after_delay(file_paths, delay=300):
    """Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø¹Ø¯ ØªØ£Ø®ÙŠØ± Ù…Ø¹ÙŠÙ† (5 Ø¯Ù‚Ø§Ø¦Ù‚ Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹)"""
    def delete_files():
        for file_path in file_paths:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    app.logger.info(f"Deleted file: {file_path}")
            except Exception as e:
                app.logger.error(f"Error deleting file {file_path}: {str(e)}")
    
    timer = Timer(delay, delete_files)
    timer.start()

def cleanup_expired_links():
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ù†ØªÙ‡ÙŠØ©"""
    current_time = datetime.now()
    expired_links = []
    
    for link_id, link_info in active_links.items():
        if current_time > link_info['expires_at'] or link_info['used']:
            expired_links.append(link_id)
    
    for link_id in expired_links:
        del active_links[link_id]
        app.logger.info(f"Cleaned up expired link: {link_id}")

# ØªØ´ØºÙŠÙ„ ØªÙ†Ø¸ÙŠÙ Ø¯ÙˆØ±ÙŠ ÙƒÙ„ Ø³Ø§Ø¹Ø©
def periodic_cleanup():
    cleanup_expired_links()
    timer = Timer(3600, periodic_cleanup)  # ÙƒÙ„ Ø³Ø§Ø¹Ø©
    timer.daemon = True
    timer.start()

periodic_cleanup()

# ==================== Routes ====================

@app.route('/')
def index():
    """Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© - Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    return render_template('link_generator.html')

@app.route('/generate-link', methods=['POST'])
def generate_link():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø¬Ø¯ÙŠØ¯ Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù ÙØ±ÙŠØ¯ Ù„Ù„Ø±Ø§Ø¨Ø·
        unique_id = str(uuid.uuid4())
        
        # ØªØ­Ø¯ÙŠØ¯ ÙˆÙ‚Øª Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ© (24 Ø³Ø§Ø¹Ø©)
        expiry_time = datetime.now() + timedelta(hours=24)
        
        # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø·
        active_links[unique_id] = {
            'created_at': datetime.now(),
            'expires_at': expiry_time,
            'used': False
        }
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„ÙƒØ§Ù…Ù„
        if request.is_secure or request.headers.get('X-Forwarded-Proto') == 'https':
            scheme = 'https'
        else:
            scheme = 'http'
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ngrok Ø£Ùˆ Ø£ÙŠ proxy
        host = request.headers.get('X-Forwarded-Host', request.host)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© Ù„Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ
        external_url = os.environ.get('EXTERNAL_URL')
        if external_url:
            host = external_url.replace('https://', '').replace('http://', '')
            scheme = 'https'
        
        link = f"{scheme}://{host}/analyze/{unique_id}"
        
        app.logger.info(f"Generated link: {link}")
        
        return jsonify({
            'success': True,
            'link': link,
            'expires_at': expiry_time.isoformat(),
            'external_url': 'ngrok' in host or 'localhost' not in host
        })
        
    except Exception as e:
        app.logger.error(f"Error generating link: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/analyze/<link_id>')
def analyze_page(link_id):
   """ØµÙØ­Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø­Ø¯Ø¯"""
   # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø·
   if link_id not in active_links:
       return render_template('error.html', 
                            error_title="Ø±Ø§Ø¨Ø· ØºÙŠØ± ØµØ§Ù„Ø­",
                            error_message="Ù‡Ø°Ø§ Ø§Ù„Ø±Ø§Ø¨Ø· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØºÙŠØ± ØµØ­ÙŠØ­",
                            error_code="404"), 404
   
   link_info = active_links[link_id]
   
   # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
   if datetime.now() > link_info['expires_at']:
       del active_links[link_id]
       return render_template('error.html',
                            error_title="Ø±Ø§Ø¨Ø· Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©",
                            error_message="Ø§Ù†ØªÙ‡Øª ØµÙ„Ø§Ø­ÙŠØ© Ù‡Ø°Ø§ Ø§Ù„Ø±Ø§Ø¨Ø·. ÙŠØ±Ø¬Ù‰ Ø·Ù„Ø¨ Ø±Ø§Ø¨Ø· Ø¬Ø¯ÙŠØ¯.",
                            error_code="410"), 410
   
   # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
   if link_info['used']:
       return render_template('error.html',
                            error_title="Ø±Ø§Ø¨Ø· Ù…Ø³ØªØ®Ø¯Ù…",
                            error_message="ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø³Ø¨Ù‚Ø§Ù‹. ÙƒÙ„ Ø±Ø§Ø¨Ø· ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·.",
                            error_code="403"), 403
   
   # Ø¹Ø±Ø¶ ØµÙØ­Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
   return render_template('mobile_analyzer.html', link_id=link_id)

@app.route('/analyze', methods=['POST'])
def analyze():
   """ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª ÙƒØ´Ù Ø§Ù„Ø­Ø³Ø§Ø¨"""
   try:
       # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ link_id
       link_id = request.form.get('link_id')
       if link_id and link_id in active_links:
           # ÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…Ø© Ø£Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡
           active_links[link_id]['used'] = True
       
       # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª
       if 'files' not in request.files:
           return jsonify({'success': False, 'error': 'Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„Ù'}), 400
       
       files = request.files.getlist('files')
       
       if not files or files[0].filename == '':
           return jsonify({'success': False, 'error': 'Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£ÙŠ Ù…Ù„Ù'}), 400
       
       # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª
       if len(files) > 5:
           return jsonify({'success': False, 'error': 'Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 5 Ù…Ù„ÙØ§Øª'}), 400
       
       saved_files = []
       
       try:
           # Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø¤Ù‚ØªØ§Ù‹
           for file in files:
               if file and allowed_file(file.filename):
                   filename = secure_filename(file.filename)
                   timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                   unique_filename = f"{timestamp}_{uuid.uuid4().hex[:8]}_{filename}"
                   file_path = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
                   file.save(file_path)
                   saved_files.append(file_path)
                   app.logger.info(f"Saved file: {file_path}")
               else:
                   return jsonify({'success': False, 'error': 'ÙŠÙØ³Ù…Ø­ ÙÙ‚Ø· Ø¨Ù…Ù„ÙØ§Øª PDF'}), 400
           
           # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
           if len(saved_files) == 1:
               # ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù ÙˆØ§Ø­Ø¯
               result = analyze_single_file(saved_files[0])
           else:
               # ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©
               result = analyze_multiple_files(saved_files)
           
           # Ø¬Ø¯ÙˆÙ„Ø© Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø¹Ø¯ 5 Ø¯Ù‚Ø§Ø¦Ù‚
           delete_files_after_delay(saved_files, 300)
           
           return jsonify({
               'success': True,
               'data': result
           })
           
       except Exception as e:
           app.logger.error(f"Error during analysis: {str(e)}")
           # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙˆØ±Ø§Ù‹ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
           for file_path in saved_files:
               try:
                   if os.path.exists(file_path):
                       os.remove(file_path)
               except:
                   pass
           
           return jsonify({
               'success': False,
               'error': f'Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª: {str(e)}'
           }), 500
           
   except Exception as e:
       app.logger.error(f"General error: {str(e)}")
       return jsonify({
           'success': False,
           'error': f'Ø®Ø·Ø£ Ø¹Ø§Ù…: {str(e)}'
       }), 500

def analyze_single_file(file_path):
   """ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯"""
   try:
       # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
       (total_rows, total_ops, inc_count, inc_sum,
        exp_count, exp_sum, skipped_rows,
        income_details, expense_details) = analyze_transactions(file_path)
       
       # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
       net_balance = inc_sum - exp_sum
       expense_percentages = calculate_expense_percentages(expense_details)
       financial_metrics = calculate_financial_metrics(income_details, expense_details)
       
       # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰
       insights = generate_insights(inc_sum, exp_sum, expense_details, financial_metrics)
       
       # Ø­Ø³Ø§Ø¨ Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨ (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
       initial_balance = inc_sum
       final_balance = net_balance
       
       # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±ØµÙŠØ¯
       balance_data = {
           'initial': initial_balance,
           'final': final_balance,
           'change': final_balance - initial_balance,
           'change_percentage': ((final_balance - initial_balance) / initial_balance * 100) if initial_balance > 0 else 0
       }
       
       # ØªÙ†Ø¸ÙŠÙ Ø£ÙˆØµØ§Ù Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
       for category, transactions in expense_details.items():
           for trans in transactions:
               trans['clean_desc'] = clean_transaction_desc(trans['desc'])
       
       for trans in income_details:
           trans['clean_desc'] = clean_transaction_desc(trans['desc'])
       
       # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
       category_stats = get_category_statistics(expense_details)
       
       # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
       categorized_expenses = prepare_categorized_expenses(category_stats)
       
       return {
           'summary': {
               'totalOperations': total_ops,
               'incomeCount': inc_count,
               'totalIncome': inc_sum,
               'expenseCount': exp_count,
               'totalExpenses': exp_sum,
               'netBalance': net_balance,
               'avgDailyExpense': financial_metrics['avg_daily_expense'],
               'maxExpense': financial_metrics['max_expense'],
               'expenseFrequency': total_ops / 30 if total_ops > 0 else 0,
               'numAccounts': 1,
               'balanceData': balance_data
           },
           'incomeDetails': income_details,
           'expenseDetails': expense_details,
           'expensePercentages': expense_percentages,
           'categorizedExpenses': categorized_expenses,  # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø¸Ù…Ø© Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
           'financialMetrics': financial_metrics,
           'insights': insights,
           'classificationMethod': 'two-level',  # Ù†Ø¸Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ
           'classificationVersion': '2.0'
       }
       
   except Exception as e:
       app.logger.error(f"Error in analyze_single_file: {str(e)}")
       raise

def analyze_multiple_files(file_paths):
   """ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬Ø¯ÙŠØ¯"""
   try:
       # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯
       (total_rows, total_ops, inc_count, inc_sum,
        exp_count, exp_sum, skipped_rows,
        income_details, expense_details) = analyze_multiple_transactions(file_paths)
       
       # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
       net_balance = inc_sum - exp_sum
       expense_percentages = calculate_expense_percentages(expense_details)
       financial_metrics = calculate_financial_metrics(income_details, expense_details)
       
       # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
       insights = generate_insights(inc_sum, exp_sum, expense_details, financial_metrics)
       
       # Ø­Ø³Ø§Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±ØµÙŠØ¯ Ù„Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
       initial_balance = inc_sum
       final_balance = net_balance
       
       balance_data = {
           'initial': initial_balance,
           'final': final_balance,
           'change': final_balance - initial_balance,
           'change_percentage': ((final_balance - initial_balance) / initial_balance * 100) if initial_balance > 0 else 0
       }
       
       # ØªÙ†Ø¸ÙŠÙ Ø£ÙˆØµØ§Ù Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
       for category, transactions in expense_details.items():
           for trans in transactions:
               trans['clean_desc'] = clean_transaction_desc(trans['desc'])
       
       for trans in income_details:
           trans['clean_desc'] = clean_transaction_desc(trans['desc'])
       
       # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
       category_stats = get_category_statistics(expense_details)
       
       # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
       categorized_expenses = prepare_categorized_expenses(category_stats)
       
       return {
           'summary': {
               'totalOperations': total_ops,
               'incomeCount': inc_count,
               'totalIncome': inc_sum,
               'expenseCount': exp_count,
               'totalExpenses': exp_sum,
               'netBalance': net_balance,
               'avgDailyExpense': financial_metrics['avg_daily_expense'],
               'maxExpense': financial_metrics['max_expense'],
               'expenseFrequency': total_ops / 30 if total_ops > 0 else 0,
               'numAccounts': len(file_paths),
               'balanceData': balance_data
           },
           'incomeDetails': income_details,
           'expenseDetails': expense_details,
           'expensePercentages': expense_percentages,
           'categorizedExpenses': categorized_expenses,
           'financialMetrics': financial_metrics,
           'insights': insights,  # Ø§Ù„Ø±Ø¤Ù‰ Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
           'classificationMethod': 'two-level',
           'classificationVersion': '2.0'
       }
       
   except Exception as e:
       app.logger.error(f"Error in analyze_multiple_files: {str(e)}")
       raise

def prepare_categorized_expenses(category_stats):
   """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµÙ†ÙØ© Ù„Ù„Ø¹Ø±Ø¶ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©"""
   categorized = []
   
   # ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¨Ù„Øº
   sorted_main = sorted(
       category_stats.items(),
       key=lambda x: x[1]['total_amount'],
       reverse=True
   )
   
   for main_category, data in sorted_main:
       # ØªØ±ØªÙŠØ¨ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©
       sorted_subs = sorted(
           data['subcategories'].items(),
           key=lambda x: x[1]['amount'],
           reverse=True
       )
       
       subcategories = []
       for sub_name, sub_data in sorted_subs:
           subcategories.append({
               'name': sub_name,
               'amount': sub_data['amount'],
               'count': sub_data['count'],
               'transactions': sub_data['transactions']
           })
       
       categorized.append({
           'mainCategory': main_category,
           'totalAmount': data['total_amount'],
           'transactionCount': data['transaction_count'],
           'subcategories': subcategories
       })
   
   return categorized

def clean_transaction_desc(desc):
   """ØªÙ†Ø¸ÙŠÙ ÙˆØµÙ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø© Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©"""
   if not desc:
       return 'Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†ÙƒÙŠØ©'
   
   clean_desc = desc
   
   # Ø¥Ø²Ø§Ù„Ø© Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹
   clean_desc = re.sub(r'\b\d{10,}\b', '', clean_desc)
   clean_desc = re.sub(r'SANBCBNK\d+', '', clean_desc)
   clean_desc = re.sub(r'\*{4,}\d{4}', '', clean_desc)
   
   # Ø¥Ø²Ø§Ù„Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨Ù†ÙˆÙƒ ÙˆØ§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
   clean_desc = re.sub(r'REMBK:.*?(?=\s|$)', '', clean_desc)
   clean_desc = re.sub(r'SWIFT:.*?(?=\s|$)', '', clean_desc)
   clean_desc = re.sub(r'IBAN:.*?(?=\s|$)', '', clean_desc)
   clean_desc = re.sub(r'BIC:.*?(?=\s|$)', '', clean_desc)
   
   # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙÙ†ÙŠØ©
   clean_desc = re.sub(r'Charges:.*?(?=\s|$)', '', clean_desc)
   clean_desc = re.sub(r'REF:.*?(?=\s|$)', '', clean_desc)
   clean_desc = re.sub(r'TRN:.*?(?=\s|$)', '', clean_desc)
   clean_desc = re.sub(r'ID:\s*\d+', '', clean_desc)
   
   # Ø¥Ø²Ø§Ù„Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
   clean_desc = re.sub(r'CHNL:.*?DEP', '', clean_desc)
   clean_desc = re.sub(r'Payment Systems.*?DEP', '', clean_desc)
   clean_desc = re.sub(r'DEP\s+\d+', '', clean_desc)
   clean_desc = re.sub(r'MCC[:\-]?\d{4}', '', clean_desc)
   
   # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
   clean_desc = re.sub(r'\s+', ' ', clean_desc).strip()
   
   # Ø¥Ø°Ø§ Ø£ØµØ¨Ø­ Ø§Ù„ÙˆØµÙ ÙØ§Ø±ØºØ§Ù‹ØŒ Ø§Ø³ØªØ®Ø¯Ù… ÙˆØµÙ Ø¹Ø§Ù…
   if not clean_desc or len(clean_desc) < 3:
       clean_desc = 'Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†ÙƒÙŠØ©'
   
   return clean_desc

@app.route('/test-classification', methods=['POST'])
def test_classification():
   """Ø§Ø®ØªØ¨Ø§Ø± ØªØµÙ†ÙŠÙ ÙˆØµÙ Ù…Ø¹Ø§Ù…Ù„Ø©"""
   try:
       data = request.get_json()
       description = data.get('description', '')
       
       if not description:
           return jsonify({
               'success': False,
               'error': 'ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ ÙˆØµÙ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø©'
           }), 400
       
       # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ
       cleaned_desc = clean_description(description)
       fixed_desc = deep_fix_arabic_text(cleaned_desc)
       
       # Ø§Ù„ØªØµÙ†ÙŠÙ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
       main_category, sub_category = classify_transaction(fixed_desc)
       
       # Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
       confidence = 0.95 if main_category != "â“ ØºÙŠØ± Ù…ØµÙ†Ù" else 0.5
       
       return jsonify({
           'success': True,
           'data': {
               'original_description': description,
               'cleaned_description': fixed_desc,
               'main_category': main_category,
               'sub_category': sub_category,
               'combined_category': f"{main_category} - {sub_category}" if sub_category != "ØºÙŠØ± Ù…Ø­Ø¯Ø¯" else main_category,
               'confidence': confidence,
               'classification_method': 'two-level',
               'version': '2.0'
           }
       })
       
   except Exception as e:
       return jsonify({
           'success': False,
           'error': str(e)
       }), 500

@app.route('/get-categories', methods=['GET'])
def get_categories():
   """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"""
   try:
       categories = []
       for main_category, subcategories in EXPENSE_CATEGORIES.items():
           category_info = {
               'name': main_category,
               'subcategories': list(subcategories.keys()),
               'keywords_count': sum(len(keywords) for keywords in subcategories.values())
           }
           categories.append(category_info)
       
       return jsonify({
           'success': True,
           'categories': categories,
           'total_main_categories': len(categories),
           'total_subcategories': sum(len(cat['subcategories']) for cat in categories)
       })
       
   except Exception as e:
       return jsonify({
           'success': False,
           'error': str(e)
       }), 500

@app.route('/health')
def health_check():
   """ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
   try:
       cleanup_expired_links()
       
       # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
       total_keywords = 0
       total_subcategories = 0
       
       for main_cat, subcats in EXPENSE_CATEGORIES.items():
           total_subcategories += len(subcats)
           for keywords in subcats.values():
               total_keywords += len(keywords)
       
       return jsonify({
           'status': 'healthy',
           'timestamp': datetime.now().isoformat(),
           'active_links': len(active_links),
           'classification_method': 'two-level',
           'classification_version': '2.0',
           'main_categories': len(EXPENSE_CATEGORIES),
           'total_subcategories': total_subcategories,
           'total_keywords': total_keywords,
           'supported_banks': ['Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ', 'Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ'],
           'version': '4.0.0'  # Ù†Ø³Ø®Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø¯Ø«
       })
   except Exception as e:
       return jsonify({
           'status': 'unhealthy',
           'error': str(e)
       }), 500

@app.route('/download-sample')
def download_sample():
   """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù PDF Ù†Ù…ÙˆØ°Ø¬ÙŠ"""
   sample_path = os.path.join('static', 'sample_statement.pdf')
   if os.path.exists(sample_path):
       return send_file(sample_path, as_attachment=True, 
                       download_name='Ù†Ù…ÙˆØ°Ø¬_ÙƒØ´Ù_Ø­Ø³Ø§Ø¨.pdf')
   else:
       return jsonify({'error': 'Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}), 404

@app.route('/api/stats')
def get_stats():
   """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
   try:
       total_keywords = 0
       total_subcategories = 0
       
       for main_cat, subcats in EXPENSE_CATEGORIES.items():
           total_subcategories += len(subcats)
           for keywords in subcats.values():
               total_keywords += len(keywords)
       
       stats = {
           'classification_version': '2.0',
           'classification_method': 'Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ (Ø±Ø¦ÙŠØ³ÙŠ ÙˆÙØ±Ø¹ÙŠ)',
           'total_main_categories': len(EXPENSE_CATEGORIES),
           'total_subcategories': total_subcategories,
           'total_keywords': total_keywords,
           'active_links': len(active_links),
           'classification_accuracy': '97%',  # ØªÙ‚Ø¯ÙŠØ±ÙŠ
           'supported_banks': ['Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ', 'Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ', 'Ø³Ø§Ù…Ø¨Ø§', 'Ø§Ù„Ø±ÙŠØ§Ø¶', 'Ø³Ø§Ø¨', 'Ø§Ù„Ø¥Ù†Ù…Ø§Ø¡'],
           'supported_formats': ['PDF'],
           'max_file_size_mb': 32,
           'max_files_per_analysis': 5
       }
       
       return jsonify({
           'success': True,
           'stats': stats
       })
       
   except Exception as e:
       return jsonify({
           'success': False,
           'error': str(e)
       }), 500

@app.errorhandler(404)
def not_found(error):
   """Ù…Ø¹Ø§Ù„Ø¬ Ø£Ø®Ø·Ø§Ø¡ 404"""
   return render_template('error.html',
                        error_title="Ø§Ù„ØµÙØ­Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©",
                        error_message="Ø§Ù„ØµÙØ­Ø© Ø§Ù„ØªÙŠ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©",
                        error_code="404"), 404

@app.errorhandler(500)
def internal_error(error):
   """Ù…Ø¹Ø§Ù„Ø¬ Ø£Ø®Ø·Ø§Ø¡ 500"""
   return render_template('error.html',
                        error_title="Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…",
                        error_message="Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰",
                        error_code="500"), 500

@app.errorhandler(413)
def request_entity_too_large(error):
   """Ù…Ø¹Ø§Ù„Ø¬ Ø£Ø®Ø·Ø§Ø¡ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„ÙƒØ¨ÙŠØ±"""
   return jsonify({
       'success': False,
       'error': 'Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹. Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ 32 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª'
   }), 413

# Context processors
@app.context_processor
def inject_now():
   """Ø­Ù‚Ù† Ø§Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ø§Ù„ÙŠ"""
   return {'now': datetime.now()}

@app.context_processor
def inject_config():
   """Ø­Ù‚Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
   return {
       'app_name': 'Ù…Ø­Ù„Ù„ ÙƒØ´Ù Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø°ÙƒÙŠ',
       'app_version': '4.0.0',
       'bank_name': 'Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø¨Ù†ÙˆÙƒ',
       'classification_method': 'Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…'
   }

# ==================== ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ====================

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
with app.app_context():
   init_db()

if __name__ == '__main__':
   # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
   use_ngrok = '--ngrok' in sys.argv or '-n' in sys.argv
   
   # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
   required_dirs = ['templates', 'static']
   for dir_name in required_dirs:
       if not os.path.exists(dir_name):
           os.makedirs(dir_name)
           safe_print(f"ğŸ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ {dir_name}")
   
   # ØªØ´ØºÙŠÙ„ Ù…Ø¹ ngrok Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨
   if use_ngrok:
       if not start_with_ngrok():
           safe_print("âŒ ÙØ´Ù„ ÙÙŠ ØªØ´ØºÙŠÙ„ ngrokØŒ Ø³ÙŠØªÙ… Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø¯ÙˆÙ†Ù‡")
   
   # Ø±Ø³Ø§Ø¦Ù„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„
   if not use_ngrok:
       print("\nğŸš€ ØªØ´ØºÙŠÙ„ Ù…Ø­Ù„Ù„ ÙƒØ´Ù Ø§Ù„Ø­Ø³Ø§Ø¨ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø¯Ø«Ø© 4.0")
       print("ğŸ”‘ ÙŠØ³ØªØ®Ø¯Ù… Ù†Ø¸Ø§Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠ (Ø±Ø¦ÙŠØ³ÙŠ + ÙØ±Ø¹ÙŠ)")
       print("ğŸ¦ ÙŠØ¯Ø¹Ù…: Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ + Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ")
       print("ğŸŒ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰: http://localhost:5000")
       print("\nğŸ’¡ Ù„ØªØ´ØºÙŠÙ„ Ù…Ø¹ ngrok Ø§Ø³ØªØ®Ø¯Ù…: python app.py --ngrok")
       print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª:")
   
   try:
       total_subcategories = sum(len(subs) for subs in EXPENSE_CATEGORIES.values())
       if not use_ngrok:
           print(f"   â€¢ {len(EXPENSE_CATEGORIES)} ØªØµÙ†ÙŠÙ Ø±Ø¦ÙŠØ³ÙŠ")
           print(f"   â€¢ {total_subcategories} ØªØµÙ†ÙŠÙ ÙØ±Ø¹ÙŠ")
           
           print("\nğŸ“‹ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:")
           for i, category in enumerate(EXPENSE_CATEGORIES.keys(), 1):
               print(f"   {i}. {category}")
           
           print(f"\nâœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­!")
           print("ğŸ¦ Ø§Ù„Ø¨Ù†ÙˆÙƒ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:")
           print("   1. Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø£Ù‡Ù„ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ")
           print("   2. Ø¨Ù†Ùƒ Ø§Ù„Ø±Ø§Ø¬Ø­ÙŠ")
       else:
           safe_print("ğŸŒŸ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†!")
           safe_print("ğŸ”— Ø§ÙØªØ­ Ø§Ù„Ù…ØªØµÙØ­ ÙˆØ§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰: http://localhost:5000")
   except Exception as e:
       error_msg = f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª: {e}"
       if use_ngrok:
           safe_print(error_msg)
       else:
           print(error_msg)
   
   # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
   try:
       app.run(host='0.0.0.0', port=5000, debug=not use_ngrok, use_reloader=False)
   except KeyboardInterrupt:
       msg = "\nğŸ‘‹ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
       if use_ngrok:
           safe_print(msg)
       else:
           print(msg)
   except Exception as e:
       error_msg = f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚: {e}"
       if use_ngrok:
           safe_print(error_msg)
       else:
           print(error_msg)
